{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ModelNet40_v1.ipynb","provenance":[{"file_id":"1bHghBO1CZ6HiFK3lIDyIUC6R_svhPSuB","timestamp":1597742228320}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-2xKG5Pgu_SX","colab_type":"text"},"source":["##### Copyright 2020 Google LLC."]},{"cell_type":"code","metadata":{"id":"-RkUBOZbu3iz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833020942,"user_tz":-120,"elapsed":1867,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"31faWJ7pCNGR"},"source":["# Point Clouds for tensorflow_graphics\n","<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/schellmi42/tensorflow_graphics_point_clouds/blob/master/pylib/notebooks/ModelNet40.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/schellmi42/tensorflow_graphics_point_clouds/blob/master/pylib/notebooks/ModelNet40.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"id":"Wo1bELqqRAKF","colab_type":"text"},"source":["## Initialization"]},{"cell_type":"markdown","metadata":{"id":"YqSeyzzZQUDV","colab_type":"text"},"source":["\n","### Clone repositories, install requirements and custom_op package"]},{"cell_type":"code","metadata":{"id":"_vtvcRP3QtTl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597833172621,"user_tz":-120,"elapsed":153344,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"d1e1a519-6282-4d4b-cece-1e0b22e3266c"},"source":["# Clone repositories\n","!rm -r tensorflow_graphics_point_clouds\n","!rm -r graphics\n","!git clone https://github.com/schellmi42/tensorflow_graphics_point_clouds\n","!git clone https://github.com/schellmi42/graphics\n","\n","# install requirements and load tfg module \n","!pip install -r graphics/requirements.txt\n","\n","# install custom ops\n","!pip install tensorflow_graphics_point_clouds/custom_ops/pkg_builds/tf_2.2.0/*.whl\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'tensorflow_graphics_point_clouds': No such file or directory\n","rm: cannot remove 'graphics': No such file or directory\n","Cloning into 'tensorflow_graphics_point_clouds'...\n","remote: Enumerating objects: 783, done.\u001b[K\n","remote: Counting objects: 100% (783/783), done.\u001b[K\n","remote: Compressing objects: 100% (511/511), done.\u001b[K\n","remote: Total 2329 (delta 564), reused 464 (delta 268), pack-reused 1546\u001b[K\n","Receiving objects: 100% (2329/2329), 23.22 MiB | 14.34 MiB/s, done.\n","Resolving deltas: 100% (1477/1477), done.\n","Cloning into 'graphics'...\n","remote: Enumerating objects: 5376, done.\u001b[K\n","remote: Total 5376 (delta 0), reused 0 (delta 0), pack-reused 5376\u001b[K\n","Receiving objects: 100% (5376/5376), 5.32 MiB | 1.20 MiB/s, done.\n","Resolving deltas: 100% (3751/3751), done.\n","Collecting tensorflow==2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 26kB/s \n","\u001b[?25hCollecting tensorflow-addons==0.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/ce/ed8472bf2b93b53702f28d91caee52181f7a10bee6eec0617a71dea12fa6/tensorflow_addons-0.10.0-cp36-cp36m-manylinux2010_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 44.8MB/s \n","\u001b[?25hCollecting tensorflow-datasets==2.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/b9/74c219b0310b3df0ac60c4948c4191b9377b6b746615b176819533096fb5/tensorflow_datasets-2.0.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 53.6MB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 4)) (0.9.0)\n","Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 5)) (2.10.0)\n","Requirement already satisfied: matplotlib>=2.2.5 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 6)) (3.2.2)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 7)) (1.18.5)\n","Collecting psutil>=5.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/3e/d18f2c04cf2b528e18515999b0c8e698c136db78f62df34eee89cee205f1/psutil-5.7.2.tar.gz (460kB)\n","\u001b[K     |████████████████████████████████| 460kB 54.5MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 9)) (1.4.1)\n","Collecting tqdm>=4.45.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/7e/281edb5bc3274dfb894d90f4dbacfceaca381c2435ec6187a2c6f329aed7/tqdm-4.48.2-py2.py3-none-any.whl (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n","\u001b[?25hCollecting OpenEXR>=1.3.2\n","  Downloading https://files.pythonhosted.org/packages/7c/c4/76bf884f59d3137847edf8b93aaf40f6257d8315d0064e8b1a606ad80b1b/OpenEXR-1.3.2.tar.gz\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 12)) (1.1.0)\n","Collecting trimesh>=2.37.22\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/f0/390e5318507be5c938e9b5714c40aa3ea6e8862f9cdaa7091b48eb0293cf/trimesh-3.8.1-py3-none-any.whl (621kB)\n","\u001b[K     |████████████████████████████████| 624kB 53.6MB/s \n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from -r graphics/requirements.txt (line 15)) (2.4)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.31.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (3.3.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.12.1)\n","Collecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 51.0MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.34.2)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.3.3)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (3.12.4)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.1.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.15.0)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 55.8MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.10.0->-r graphics/requirements.txt (line 2)) (2.7.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (0.22.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (0.16.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (19.3.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (0.3.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.5->-r graphics/requirements.txt (line 6)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.5->-r graphics/requirements.txt (line 6)) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.5->-r graphics/requirements.txt (line 6)) (2.8.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.5->-r graphics/requirements.txt (line 6)) (2.4.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from trimesh>=2.37.22->-r graphics/requirements.txt (line 13)) (49.2.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->-r graphics/requirements.txt (line 15)) (4.4.2)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.4.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.7.0)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.17.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (3.2.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow-datasets==2.0.0->-r graphics/requirements.txt (line 3)) (1.52.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (4.1.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (1.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow==2.2.0->-r graphics/requirements.txt (line 1)) (3.1.0)\n","Building wheels for collected packages: psutil, OpenEXR\n","  Building wheel for psutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for psutil: filename=psutil-5.7.2-cp36-cp36m-linux_x86_64.whl size=279881 sha256=4ba559a7c8258766a34ef66e3c6c64987e418a9e6ec1bec18ab73afb7b7fdc4c\n","  Stored in directory: /root/.cache/pip/wheels/39/a0/f5/c4fa280463e29aea07797acb5312358fefb067c1f4f98e11b1\n","  Building wheel for OpenEXR (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for OpenEXR: filename=OpenEXR-1.3.2-cp36-cp36m-linux_x86_64.whl size=188432 sha256=416156380e4d3bb1e6d67fb3581695dea91c1ea3b64751c0d1927a950c63ec7f\n","  Stored in directory: /root/.cache/pip/wheels/41/06/9f/c7dc838815b0e7dfc7d7dc19cc3d677edb47594d8489adc62a\n","Successfully built psutil OpenEXR\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow, tensorflow-addons, tqdm, tensorflow-datasets, psutil, OpenEXR, trimesh\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","  Found existing installation: tensorflow-addons 0.8.3\n","    Uninstalling tensorflow-addons-0.8.3:\n","      Successfully uninstalled tensorflow-addons-0.8.3\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","  Found existing installation: tensorflow-datasets 2.1.0\n","    Uninstalling tensorflow-datasets-2.1.0:\n","      Successfully uninstalled tensorflow-datasets-2.1.0\n","  Found existing installation: psutil 5.4.8\n","    Uninstalling psutil-5.4.8:\n","      Successfully uninstalled psutil-5.4.8\n","Successfully installed OpenEXR-1.3.2 psutil-5.7.2 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-addons-0.10.0 tensorflow-datasets-2.0.0 tensorflow-estimator-2.2.0 tqdm-4.48.2 trimesh-3.8.1\n","Processing ./tensorflow_graphics_point_clouds/custom_ops/pkg_builds/tf_2.2.0/tfg_custom_ops-0.0.1-cp36-cp36m-linux_x86_64.whl\n","Installing collected packages: tfg-custom-ops\n","Successfully installed tfg-custom-ops-0.0.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9D-q8bUu7TcJ","colab_type":"text"},"source":["### Load modules"]},{"cell_type":"code","metadata":{"id":"5lTxNysx7Lfz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833172624,"user_tz":-120,"elapsed":153339,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["import sys\n","# (this is equivalent to export PYTHONPATH='$HOME/graphics:/content/graphics:$PYTHONPATH', but adds path to running session)\n","sys.path.append(\"/content/graphics\")\n","\n","# load point cloud module \n","# (this is equivalent to export PYTHONPATH='/content/tensorflow_graphics_point_clouds:$PYTHONPATH', but adds path to running session)\n","sys.path.append(\"/content/tensorflow_graphics_point_clouds\")"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gUTDsKERxWh","colab_type":"text"},"source":["Check if it loads without errors"]},{"cell_type":"code","metadata":{"id":"Z_49mMLOSOX6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1597833177713,"user_tz":-120,"elapsed":158409,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"747d8354-4bb2-4f2e-e3d3-45ce90e1d7a0"},"source":["import tensorflow as tf\n","import tensorflow_graphics as tfg\n","import MCCNN2.pc as pc\n","import numpy as np\n","\n","print('TensorFlow version: %s'%tf.__version__)\n","print('TensorFlow-Graphics version: %s'%tfg.__version__)\n","print('Point Cloud Module: ', pc)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["TensorFlow version: 2.2.0\n","TensorFlow-Graphics version: HEAD\n","Point Cloud Module:  <module 'MCCNN2.pc' from '/content/tensorflow_graphics_point_clouds/MCCNN2/pc/__init__.py'>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1_XXAVBau-gg","colab_type":"text"},"source":["## Classification on ModelNet40"]},{"cell_type":"markdown","metadata":{"id":"dVQV3Ykr16m8","colab_type":"text"},"source":["### Data preparation"]},{"cell_type":"markdown","metadata":{"id":"WIXyqlmBv5q1","colab_type":"text"},"source":["First we load the data consisting of 10k points per model."]},{"cell_type":"code","metadata":{"id":"GW4GZdArv-3g","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"ok","timestamp":1597833495427,"user_tz":-120,"elapsed":476112,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"0256db54-58c6-48ba-fab1-e5681cdafa02"},"source":["!wget --no-check-certificate https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip \n","!echo '---unzipping---'\n","!unzip -q modelnet40_normal_resampled.zip \n","!echo '[done]'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-08-19 10:32:56--  https://shapenet.cs.stanford.edu/media/modelnet40_normal_resampled.zip\n","Resolving shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)... 171.67.77.19\n","Connecting to shapenet.cs.stanford.edu (shapenet.cs.stanford.edu)|171.67.77.19|:443... connected.\n","WARNING: cannot verify shapenet.cs.stanford.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n","  Issued certificate has expired.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1705117335 (1.6G) [application/zip]\n","Saving to: ‘modelnet40_normal_resampled.zip’\n","\n","modelnet40_normal_r 100%[===================>]   1.59G  4.83MB/s    in 2m 48s  \n","\n","2020-08-19 10:35:44 (9.69 MB/s) - ‘modelnet40_normal_resampled.zip’ saved [1705117335/1705117335]\n","\n","---unzipping---\n","[done]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qd2ElOdHwBnW","colab_type":"text"},"source":["Next we load the data, using the input function in the `io` module.\n","\n","To speed up this tutorial, we only load a subset of the points per model.\n","\n"]},{"cell_type":"code","metadata":{"id":"Bnt1Byd4sWHi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"executionInfo":{"status":"ok","timestamp":1597833919783,"user_tz":-120,"elapsed":900459,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"3d98279e-b420-437b-a9d5-9dccb0a77f59"},"source":["import tensorflow as tf \n","import MCCNN2.pc as pc\n","import MCCNN2.io as io\n","import numpy as np\n","import tensorflow_graphics\n","import os, time\n","\n","\n","quick_test = False  # only load 100 models\n","\n","# -- loading data ---\n","\n","data_dir = 'modelnet40_normal_resampled/'\n","num_classes = 40  # modelnet 10 or 40\n","points_per_file = 5000  # number of points loaded per model\n","\n","# load category names\n","category_names = []\n","with open(data_dir + f'modelnet{num_classes}_shape_names.txt') as inFile:\n","  for line in inFile:\n","    category_names.append(line.replace('\\n', ''))\n","\n","# load names of training files\n","train_set = []\n","train_labels = []\n","with open(data_dir + f'modelnet{num_classes}_train.txt') as inFile:\n","  for line in inFile:\n","    line = line.replace('\\n', '')\n","    category = line[:-5]\n","    train_set.append(data_dir + category + '/' + line + '.txt')\n","    if category not in category_names:\n","      raise ValueError('Unknown category ' + category)\n","    train_labels.append(category_names.index(category))\n","\n","# load names of test files\n","test_set = []\n","test_labels = []\n","with open(data_dir + f'modelnet{num_classes}_test.txt') as inFile:\n","  for line in inFile:\n","    line = line.replace('\\n', '')\n","    category = line[:-5]\n","    test_set.append(data_dir + category + '/' + line + '.txt')\n","    if category not in category_names:\n","      raise ValueError('Unknown category ' + category)\n","    test_labels.append(category_names.index(category))\n","\n","# load training data\n","train_data_points = np.empty([len(train_set), points_per_file, 3])\n","\n","print(f'### loading modelnet{num_classes} train ###')\n","for i, filename in enumerate(train_set):\n","  points, _ = \\\n","      io.load_points_from_file_to_numpy(filename,\n","                                        max_num_points=points_per_file)\n","  train_data_points[i] = points\n","  if i % 500 == 0:\n","    print(f'{i}/{len(train_set)}')\n","  if quick_test and i > 100:\n","    break\n","\n","# load test data\n","test_data_points = np.empty([len(test_set), points_per_file, 3])\n","\n","print(f'### loading modelnet{num_classes} test ###')\n","for i, filename in enumerate(test_set):\n","  points, _ = \\\n","      io.load_points_from_file_to_numpy(filename,\n","                                        max_num_points=points_per_file)\n","  test_data_points[i] = points\n","  if i % 500 == 0:\n","    print(f'{i}/{len(test_set)}')\n","  if quick_test and i > 100:\n","    break"],"execution_count":6,"outputs":[{"output_type":"stream","text":["### loading modelnet40 train ###\n","0/9843\n","500/9843\n","1000/9843\n","1500/9843\n","2000/9843\n","2500/9843\n","3000/9843\n","3500/9843\n","4000/9843\n","4500/9843\n","5000/9843\n","5500/9843\n","6000/9843\n","6500/9843\n","7000/9843\n","7500/9843\n","8000/9843\n","8500/9843\n","9000/9843\n","9500/9843\n","### loading modelnet40 test ###\n","0/2468\n","500/2468\n","1000/2468\n","1500/2468\n","2000/2468\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W7a1wLiPxCb3","colab_type":"text"},"source":["Now let's define a small data loader.\n","\n","To make the network evaluation faster, we randomly samples the point clouds to reduce the input size.\n","\n","As we don't want to provide any additional features other than the point location to the network, we will use a constant `1` as input feature.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"NPJ9chpWxHNH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833919836,"user_tz":-120,"elapsed":900507,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["class modelnet_data_generator(tf.keras.utils.Sequence):\n","  ''' Small generator of batched data.\n","  '''\n","  def __init__(self,\n","               points,\n","               labels,\n","               batch_size):\n","      self.points = points\n","      self.labels = np.array(labels, dtype=int)\n","      self.batch_size = batch_size\n","      self.epoch_size = len(self.points)\n","\n","      self.ids = np.arange(0, points_per_file)\n","      # shuffle data before training\n","      self.on_epoch_end()\n","\n","  def __len__(self):\n","    # number of batches per epoch\n","    return(int(np.floor(self.epoch_size / self.batch_size)))\n","\n","  def __call__(self):\n","    ''' Loads batch and increases batch index.\n","    '''\n","    data = self.__getitem__(self.index)\n","    self.index += 1\n","    return data\n","\n","  def __getitem__(self, index, samples_per_model=1024):\n","    ''' Loads data of current batch and samples random subset of the points.\n","    '''\n","    labels = \\\n","        self.labels[index * self.batch_size:(index + 1) * self.batch_size]\n","    points = \\\n","        self.points[index * self.batch_size:(index + 1) * self.batch_size]\n","    # constant input feature\n","    features = tf.ones([self.batch_size, samples_per_model, 1])\n","\n","    # sample points\n","    sampled_points = np.empty([self.batch_size, samples_per_model, 3])\n","    for batch in range(self.batch_size):\n","      selection = np.random.choice(self.ids, samples_per_model)\n","      sampled_points[batch] = points[batch][selection]\n","\n","    return sampled_points, features, labels\n","\n","  def on_epoch_end(self):\n","    ''' Shuffles data and resets batch index.\n","    '''\n","    shuffle = np.random.permutation(np.arange(0, len(self.points)))\n","    self.points = self.points[shuffle]\n","    self.labels = self.labels[shuffle]\n","    self.index = 0"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"txT-ddp_wTd0","colab_type":"text"},"source":["### Network architecture\n","\n","Let's build a simple classification network, which uses point convolutions for encoding the shape, and two dense layers for predicting the class.\n","\n","The following model contains example calls for the three different available point convolutions in the `layer` module:\n","\n","\n","*   [Monte-Carlo convolutions](https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.100/institut/Papers/viscom/2018/hermosilla2018montecarlo.pdf), which uses MLPs for representing the convolutional kernel, and aggregates the features inside the convolution radius using [Monte-Carlo integration](https://en.wikipedia.org/wiki/Monte_Carlo_integration), where each feature is weighted by a point density estimation.\n","*   [Kernel Point convolutions](https://arxiv.org/pdf/1904.08889.pdf), where the convolutional kernel is represented by a set of weights on kernel points, which are interpolated. \n","(Note: We use rigid kernel points in the example below but deformable kernel points are also supported)\n","\n","*   [PointConv convolutions](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.pdf)\n",", which uses a single MLP for representing the convolutional kernel, and aggregates the features using an integration, where each feature is weighted by a learned inverse density estimation.\n","\n","\n","Note that different to an image convolution layer, a point convolution layer needs additional input about the spatial location of the features, i.e. point coordinates.\n","In case of a 'strided' point convolution, where the output features are defined on different points than the input, we have to provide two point clouds.\n","\n","For sampling the point clouds to lower densities, we use the `PointHierarchy` class.\n","\n","At the end of the encoder we use a `GlobalAveragePooling` layer to aggregate the features from all points into one latent vector. "]},{"cell_type":"code","metadata":{"id":"sGC3q1drt60i","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597833919839,"user_tz":-120,"elapsed":900504,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["from MCCNN2.pc import layers\n","\n","class mymodel(tf.keras.Model):\n","  ''' Model architecture with `L` convolutional layers followed by \n","  two dense layers.\n","\n","  Args:\n","    features_sizes: A `list` of `ints`, the feature dimensions. Shape `[L+3]`.\n","    sample_radii: A `list` of `floats, the radii used for sampling\n","      of the point clouds. Shape `[L]`.\n","    conv_radii: A `list` of `floats`, the radii used by the convolution\n","      layers. Shape `[L]`.\n","    layer_type: A `string`, the type of convolution used,\n","      can be 'MCConv', 'KPConv', 'PointConv'.\n","    sampling_method: 'poisson disk' or 'cell average'.\n","  '''\n","\n","  def __init__(self,\n","               feature_sizes,\n","               sample_radii,\n","               conv_radii,\n","               layer_type='MCConv',\n","               sampling_method='poisson disk'):\n","    super(mymodel, self).__init__()\n","    self.num_layers = len(sample_radii)\n","    self.sample_radii = sample_radii.reshape(-1,1)\n","    self.conv_radii = conv_radii\n","    self.sampling_method = sampling_method\n","    self.conv_layers = []\n","    self.batch_layers = []\n","    self.dense_layers = []\n","    self.activations = []\n","    # encoder\n","    for i in range(self.num_layers):\n","      # convolutional downsampling layers\n","      if layer_type == 'MCConv':\n","        self.conv_layers.append(layers.MCConv(\n","            num_features_in=feature_sizes[i],\n","            num_features_out=feature_sizes[i + 1],\n","            num_dims=3,\n","            num_mlps=4,\n","            mlp_size=[8]))\n","      elif layer_type == 'PointConv':\n","        self.conv_layers.append(layers.PointConv(\n","            num_features_in=feature_sizes[i],\n","            num_features_out=feature_sizes[i + 1],\n","            num_dims=3,\n","            size_hidden=32))\n","      elif layer_type == 'KPConv':\n","        self.conv_layers.append(layers.KPConv(\n","            num_features_in=feature_sizes[i],\n","            num_features_out=feature_sizes[i + 1],\n","            num_dims=3,\n","            num_kernel_points=15))\n","      else:\n","        raise ValueError(\"Unknown layer type!\")\n","      if i < self.num_layers-1:\n","        # batch normalization and activation function\n","        self.batch_layers.append(tf.keras.layers.BatchNormalization())\n","        self.activations.append(tf.keras.layers.LeakyReLU())\n","    # global pooling\n","    self.global_pooling = layers.GlobalAveragePooling()\n","    self.batch_layers.append(tf.keras.layers.BatchNormalization())\n","    self.activations.append(tf.keras.layers.LeakyReLU())\n","    # MLP\n","    self.dense_layers.append(tf.keras.layers.Dense(feature_sizes[-2]))\n","    self.batch_layers.append(tf.keras.layers.BatchNormalization())\n","    self.activations.append(tf.keras.layers.LeakyReLU())\n","    self.dense_layers.append(tf.keras.layers.Dense(feature_sizes[-1]))\n","\n","  def __call__(self,\n","               points,\n","               features,\n","               training):\n","    ''' Evaluates network.\n","\n","    Args:\n","      points: The point coordinates. Shape `[B, N, 3]`.\n","      features: Input features. Shape `[B, N, C]`.\n","      training: A `bool`, passed to the batch norm layers.\n","\n","    Returns:\n","      The logits per class.\n","    '''\n","    sample_radii = self.sample_radii\n","    conv_radii = self.conv_radii\n","    sampling_method = self.sampling_method\n","    # input point cloud\n","    # Note: Here all point clouds have the same number of points, so no `sizes`\n","    #       or `batch_ids` are passed.\n","    point_cloud = pc.PointCloud(points)\n","    # spatial downsampling\n","    point_hierarchy = pc.PointHierarchy(point_cloud,\n","                                        sample_radii,\n","                                        sampling_method)\n","    # network evaluation\n","    for i in range(self.num_layers):\n","      features = self.conv_layers[i](features,\n","                                     point_hierarchy[i], \n","                                     point_hierarchy[i+1],\n","                                     conv_radii[i])\n","      if i < self.num_layers-1:\n","        features = self.batch_layers[i](features, training=training)\n","        features = self.activations[i](features)\n","    # classification head\n","    features = self.global_pooling(features, point_hierarchy[-1])\n","    features = self.batch_layers[-2](features, training)\n","    features = self.activations[-2](features)\n","    features = self.dense_layers[-2](features)\n","    features = self.batch_layers[-1](features, training)\n","    features = self.activations[-1](features)\n","    return self.dense_layers[-1](features)\n"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WureY8ZixvlG","colab_type":"text"},"source":["### Model parameters"]},{"cell_type":"code","metadata":{"id":"U0pnDkbZxpxP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597836777710,"user_tz":-120,"elapsed":2862,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["batch_size = 16\n","\n","feature_sizes = [1, 128, 256, 512, 128, num_classes]\n","sample_radii = np.array([0.1, 0.2, 0.4])\n","conv_radii = sample_radii * 1.5\n","\n","# initialize data generators\n","gen_train = modelnet_data_generator(train_data_points, train_labels, batch_size)\n","gen_test = modelnet_data_generator(test_data_points, test_labels, batch_size)\n","\n","# loss function and optimizer\n","loss_function = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","lr_decay=tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.01,\n","    decay_steps=len(gen_train),\n","    decay_rate=0.95)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=lr_decay)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AJjR2m9Fx68-","colab_type":"text"},"source":["### Training Loop"]},{"cell_type":"code","metadata":{"id":"AzolzewtyDcU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597836791466,"user_tz":-120,"elapsed":920,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}}},"source":["def training(model,\n","             optimizer,\n","             loss_function,\n","             num_epochs = 10,\n","             epochs_print=1):\n","  train_loss_results = []\n","  train_accuracy_results = []\n","  test_loss_results = []\n","  test_accuracy_results = []\n","\n","  for epoch in range(num_epochs):\n","    time_epoch_start = time.time()\n","\n","    # --- Training ---\n","    epoch_loss_avg = tf.keras.metrics.Mean()\n","    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","    for points, features, labels in gen_train:\n","      # evaluate model; forward pass\n","      with tf.GradientTape() as tape:\n","        logits = model(points, features, training=True)\n","        pred = tf.nn.softmax(logits, axis=-1)\n","        loss = loss_function(y_true=labels, y_pred=pred)\n","      # backpropagation\n","      grads = tape.gradient(loss, model.trainable_variables)\n","      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      epoch_loss_avg.update_state(loss)\n","      epoch_accuracy.update_state(labels, pred)\n","\n","    train_loss_results.append(epoch_loss_avg.result())\n","    train_accuracy_results.append(epoch_accuracy.result())\n","\n","    # --- Validation ---\n","    epoch_loss_avg = tf.keras.metrics.Mean()\n","    epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n","\n","    for points, features, labels in gen_test:\n","      # evaluate model; forward pass\n","      logits = model(points, features, training=False)\n","      pred = tf.nn.softmax(logits, axis=-1)\n","      loss = loss_function(y_true=labels, y_pred=pred)\n","\n","      epoch_loss_avg.update_state(loss)\n","      epoch_accuracy.update_state(labels, pred)\n","\n","    test_loss_results.append(epoch_loss_avg.result())\n","    test_accuracy_results.append(epoch_accuracy.result())\n","\n","    time_epoch_end = time.time()\n","\n","    if epoch % epochs_print == 0:\n","      # End epoch\n","      print('Epoch {:03d} Time: {:.3f}s'.format(\n","          epoch,\n","          time_epoch_end - time_epoch_start))\n","      print('Training:   Loss: {:.3f}, Accuracy: {:.3%}'.format(\n","          train_loss_results[-1],\n","          train_accuracy_results[-1]))\n","      print('Validation: Loss: {:.3f}, Accuracy: {:.3%}'.format(\n","          test_loss_results[-1],\n","          test_accuracy_results[-1]))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CIALtH8TzagI","colab_type":"text"},"source":["#### Train with [Monte-Carlo convolutions](https://www.uni-ulm.de/fileadmin/website_uni_ulm/iui.inst.100/institut/Papers/viscom/2018/hermosilla2018montecarlo.pdf)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e-jbnyGaCrfE","colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"status":"ok","timestamp":1597837726954,"user_tz":-120,"elapsed":933778,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"47f7d8f5-69f6-4ee3-ae59-12634d066b8d"},"source":["model_MC = mymodel(feature_sizes, sample_radii, conv_radii,\n","                   layer_type='MCConv')\n","training(model_MC, optimizer, loss_function)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Epoch 000 Time: 92.980s\n","Training:   Loss: 1.424, Accuracy: 61.230%\n","Validation: Loss: 1.281, Accuracy: 61.242%\n","Epoch 001 Time: 92.852s\n","Training:   Loss: 0.963, Accuracy: 71.514%\n","Validation: Loss: 0.890, Accuracy: 73.742%\n","Epoch 002 Time: 93.179s\n","Training:   Loss: 0.846, Accuracy: 74.543%\n","Validation: Loss: 0.792, Accuracy: 76.907%\n","Epoch 003 Time: 94.161s\n","Training:   Loss: 0.789, Accuracy: 76.108%\n","Validation: Loss: 0.779, Accuracy: 76.705%\n","Epoch 004 Time: 92.779s\n","Training:   Loss: 0.725, Accuracy: 77.825%\n","Validation: Loss: 0.785, Accuracy: 76.542%\n","Epoch 005 Time: 94.349s\n","Training:   Loss: 0.691, Accuracy: 78.974%\n","Validation: Loss: 0.770, Accuracy: 77.273%\n","Epoch 006 Time: 94.105s\n","Training:   Loss: 0.653, Accuracy: 79.512%\n","Validation: Loss: 0.738, Accuracy: 77.719%\n","Epoch 007 Time: 92.037s\n","Training:   Loss: 0.626, Accuracy: 80.142%\n","Validation: Loss: 0.695, Accuracy: 79.667%\n","Epoch 008 Time: 92.787s\n","Training:   Loss: 0.591, Accuracy: 81.453%\n","Validation: Loss: 0.681, Accuracy: 79.992%\n","Epoch 009 Time: 93.393s\n","Training:   Loss: 0.569, Accuracy: 81.657%\n","Validation: Loss: 0.695, Accuracy: 78.653%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zY-6sJnRzXvl","colab_type":"text"},"source":["#### Train with [Kernel Point convolutions](https://arxiv.org/pdf/1904.08889.pdf).\n","\n","To use the cell average sampling used in the paper, we can simply change the sampling method, which is passed to the point hierarchy constructor."]},{"cell_type":"code","metadata":{"id":"n03SZUTgzYoc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"status":"ok","timestamp":1597839162210,"user_tz":-120,"elapsed":657522,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"6000ee9a-8f6f-44a7-ef92-076bdfd8f90d"},"source":["model_KP = mymodel(feature_sizes, sample_radii, conv_radii,\n","                   layer_type='KPConv', sampling_method='cell average')\n","training(model_KP, optimizer, loss_function)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 000 Time: 65.052s\n","Training:   Loss: 1.780, Accuracy: 53.191%\n","Validation: Loss: 1.504, Accuracy: 56.291%\n","Epoch 001 Time: 65.114s\n","Training:   Loss: 1.277, Accuracy: 63.984%\n","Validation: Loss: 1.332, Accuracy: 61.364%\n","Epoch 002 Time: 65.933s\n","Training:   Loss: 1.130, Accuracy: 67.754%\n","Validation: Loss: 1.178, Accuracy: 66.071%\n","Epoch 003 Time: 65.731s\n","Training:   Loss: 1.057, Accuracy: 69.157%\n","Validation: Loss: 1.241, Accuracy: 65.016%\n","Epoch 004 Time: 65.608s\n","Training:   Loss: 0.982, Accuracy: 71.280%\n","Validation: Loss: 1.146, Accuracy: 67.208%\n","Epoch 005 Time: 65.204s\n","Training:   Loss: 0.922, Accuracy: 72.561%\n","Validation: Loss: 1.104, Accuracy: 68.669%\n","Epoch 006 Time: 65.882s\n","Training:   Loss: 0.876, Accuracy: 73.709%\n","Validation: Loss: 1.078, Accuracy: 68.912%\n","Epoch 007 Time: 66.951s\n","Training:   Loss: 0.831, Accuracy: 74.766%\n","Validation: Loss: 1.084, Accuracy: 70.414%\n","Epoch 008 Time: 65.414s\n","Training:   Loss: 0.791, Accuracy: 76.189%\n","Validation: Loss: 1.041, Accuracy: 71.469%\n","Epoch 009 Time: 65.705s\n","Training:   Loss: 0.755, Accuracy: 77.409%\n","Validation: Loss: 1.050, Accuracy: 70.414%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ak7hMQeWzZZq","colab_type":"text"},"source":["#### Train with [PointConv convolutions](https://openaccess.thecvf.com/content_CVPR_2019/papers/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.pdf)."]},{"cell_type":"code","metadata":{"id":"wj9T-UaCzZ4z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"status":"ok","timestamp":1597840065018,"user_tz":-120,"elapsed":1558003,"user":{"displayName":"Michael Schelling","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNlUbYgAsRJSdhU27HkyCQRj1VILg21SHN-gfZ=s64","userId":"09654458763205012748"}},"outputId":"344f88a4-3074-4a7d-dd4a-1a59e6cb545f"},"source":["model_PC = mymodel(feature_sizes, sample_radii, conv_radii,\n","                   layer_type='PointConv')\n","training(model_PC, optimizer, loss_function)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Epoch 000 Time: 90.527s\n","Training:   Loss: 1.607, Accuracy: 56.911%\n","Validation: Loss: 1.207, Accuracy: 62.906%\n","Epoch 001 Time: 92.304s\n","Training:   Loss: 1.022, Accuracy: 69.705%\n","Validation: Loss: 1.041, Accuracy: 69.643%\n","Epoch 002 Time: 88.655s\n","Training:   Loss: 0.884, Accuracy: 73.862%\n","Validation: Loss: 0.860, Accuracy: 75.041%\n","Epoch 003 Time: 88.859s\n","Training:   Loss: 0.813, Accuracy: 75.376%\n","Validation: Loss: 0.825, Accuracy: 76.420%\n","Epoch 004 Time: 92.573s\n","Training:   Loss: 0.762, Accuracy: 76.646%\n","Validation: Loss: 0.781, Accuracy: 76.420%\n","Epoch 005 Time: 92.357s\n","Training:   Loss: 0.715, Accuracy: 78.181%\n","Validation: Loss: 0.747, Accuracy: 78.328%\n","Epoch 006 Time: 90.531s\n","Training:   Loss: 0.688, Accuracy: 78.262%\n","Validation: Loss: 0.750, Accuracy: 77.800%\n","Epoch 007 Time: 89.183s\n","Training:   Loss: 0.650, Accuracy: 79.959%\n","Validation: Loss: 0.736, Accuracy: 78.896%\n","Epoch 008 Time: 90.951s\n","Training:   Loss: 0.631, Accuracy: 79.980%\n","Validation: Loss: 0.746, Accuracy: 77.679%\n","Epoch 009 Time: 86.768s\n","Training:   Loss: 0.611, Accuracy: 80.610%\n","Validation: Loss: 0.726, Accuracy: 79.343%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"njP1uIRCjXJT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}